{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd60ac1-8a78-4bb1-a7c4-8a7dc5ff34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b8c73b-8337-4f89-8b7f-2ce1ad0271b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19989fe-c7da-4bdd-8d50-bd594e2ce97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x000002A89B13A380>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x000002A89B13BB20>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x000002A89E892DC0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x000002A89ED064C0>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x000002A89EC4F680>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x000002A89E892E30>)]\n"
     ]
    }
   ],
   "source": [
    "# nlp.pipe_names # OR\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169e329f-07f8-4432-85ac-207dbc8c1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"The central data structures in spaCy are the Language class, the Vocab and the Doc object. The Language class is used to process a text and turn it into a Doc object. It’s typically stored as a variable called nlp. The Doc object owns the sequence of tokens and all their annotations. By centralizing strings, word vectors and lexical attributes in the Vocab, we avoid storing multiple copies of this data. This saves memory, and ensures there’s a single source of truth.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec01cbd-a786-4f47-b17e-0cb2e6248672",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc =  nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78e087fc-9982-4854-bbd1-9a3803451809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The central data structures in spaCy are the Language class, the Vocab and the Doc object. The Language class is used to process a text and turn it into a Doc object. It’s typically stored as a variable called nlp. The Doc object owns the sequence of tokens and all their annotations. By centralizing strings, word vectors and lexical attributes in the Vocab, we avoid storing multiple copies of this data. This saves memory, and ensures there’s a single source of truth."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa25693-7b30-413b-b7b5-2cfd5220cf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.85473725292134"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c457aa7f-6d25-4423-8574-1822b75e7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c4f71e3-45ec-4093-8406-07f2adf75791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize the nlp pippeline\n",
    "\n",
    "def len_of_doc(doc):\n",
    "    print(\"length of doc :\",len(doc))\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31500a5e-8e6c-4165-ab9f-0b20daec3266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of doc : 471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The central data structures in spaCy are the Language class, the Vocab and the Doc object. The Language class is used to process a text and turn it into a Doc object. It’s typically stored as a variable called nlp. The Doc object owns the sequence of tokens and all their annotations. By centralizing strings, word vectors and lexical attributes in the Vocab, we avoid storing multiple copies of this data. This saves memory, and ensures there’s a single source of truth.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_of_doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52d6e0bf-05a7-4cab-8efd-98f9dc7bad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mnlpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfactory_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mraw_config\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconfection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Create a pipeline component. Mostly used internally. To create and\n",
       "add a component to the pipeline, you can use nlp.add_pipe.\n",
       "\n",
       "factory_name (str): Name of component factory.\n",
       "name (Optional[str]): Optional name to assign to component instance.\n",
       "    Defaults to factory name if not set.\n",
       "config (Dict[str, Any]): Config parameters to use for this component.\n",
       "    Will be merged with default config, if available.\n",
       "raw_config (Optional[Config]): Internals: the non-interpolated config.\n",
       "validate (bool): Whether to validate the component config against the\n",
       "    arguments and types expected by the factory.\n",
       "RETURNS (Callable[[Doc], Doc]): The pipeline component.\n",
       "\n",
       "DOCS: https://spacy.io/api/language#create_pipe\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\izhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\spacy\\language.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlpp.create_pipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548847ae-f098-4ad5-a202-2a989e6c8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpp.add_pipe(\"attribute_ruler\",first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76407d6b-8ae3-4229-9e41-73cfb3308b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfactory_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbefore\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mafter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfirst\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlast\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Language'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mraw_config\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconfection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Add a component to the processing pipeline. Valid components are\n",
       "callables that take a `Doc` object, modify it and return it. Only one\n",
       "of before/after/first/last can be set. Default behaviour is \"last\".\n",
       "\n",
       "factory_name (str): Name of the component factory.\n",
       "name (str): Name of pipeline component. Overwrites existing\n",
       "    component.name attribute if available. If no name is set and\n",
       "    the component exposes no name attribute, component.__name__ is\n",
       "    used. An error is raised if a name already exists in the pipeline.\n",
       "before (Union[str, int]): Name or index of the component to insert new\n",
       "    component directly before.\n",
       "after (Union[str, int]): Name or index of the component to insert new\n",
       "    component directly after.\n",
       "first (bool): If True, insert component first in the pipeline.\n",
       "last (bool): If True, insert component last in the pipeline.\n",
       "source (Language): Optional loaded nlp object to copy the pipeline\n",
       "    component from.\n",
       "config (Dict[str, Any]): Config parameters to use for this component.\n",
       "    Will be merged with default config, if available.\n",
       "raw_config (Optional[Config]): Internals: the non-interpolated config.\n",
       "validate (bool): Whether to validate the component config against the\n",
       "    arguments and types expected by the factory.\n",
       "RETURNS (Callable[[Doc], Doc]): The pipeline component.\n",
       "\n",
       "DOCS: https://spacy.io/api/language#add_pipe\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\izhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\spacy\\language.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.add_pipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1981665-2391-4942-9f0f-6975296ddee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom component\n",
    "def length_component(doc):\n",
    "    # Get the doc's length\n",
    "    doc_length = len(doc)\n",
    "    print(\"This document is {} tokens long.\".format(doc_length))\n",
    "    # Return the doc\n",
    "    return doc\n",
    "  \n",
    "# Load the small English model and Add the component first in the pipeline\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(length_component, first=True)\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"This is a sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4179b3b-abb5-48fe-99c0-f9522aba643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom component\n",
    "def animal_component(doc):\n",
    "    # Create a Span for each match and assign the label 'ANIMAL'\n",
    "    # and overwrite the doc.ents with the matched spans\n",
    "    doc.ents = [Span(doc, start, end, label='ANIMAL')\n",
    "                for match_id, start, end in matcher(doc)]\n",
    "    return doc\n",
    "    \n",
    "# Add the component to the pipeline after the 'ner' component \n",
    "nlp.add_pipe(animal_component, after='ner')\n",
    "\n",
    "# Process the text and print the text and label for the doc.ents\n",
    "doc = nlp(\"I have a cat and a Golden Retriever\")\n",
    "print([(____, ____) for ent in ____])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8877938c-a9d8-40f2-bb10-58213576ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = \"\"\"Create a pipeline component. Mostly used internally. To create and\n",
    "add a component to the pipeline, you can use nlp.add_pipe.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652007f5-84c9-435b-9cdc-0f67dba4940b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05dd1e9-f649-47fb-a87b-b3aba507b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9db50df-07fb-41f7-a5c7-63fc81ad00a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Disable a pipeline component. The component will still exist on\n",
       "the nlp object, but it won't be run as part of the pipeline. Does\n",
       "nothing if the component is already disabled.\n",
       "\n",
       "name (str): The name of the component to disable.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\izhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\spacy\\language.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.disable_pipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4324b3c-fdc9-48c4-a7cb-fd3d5a4f42e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959657fc-c76c-48bd-8b97-77aad89b9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.disable_pipe(name='tagger') as n:\n",
    "    doc = n(t1)\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71758aae-2bec-41f8-9fed-079f92503a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b02b6d58-70a7-4307-9589-3ab47837729c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_pipes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DisabledPipes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Disable one or more pipeline components. If used as a context\n",
       "manager, the pipeline will be restored to the initial state at the end\n",
       "of the block. Otherwise, a DisabledPipes object is returned, that has\n",
       "a `.restore()` method you can use to undo your changes.\n",
       "\n",
       "This method has been deprecated since 3.0\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\izhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\spacy\\language.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.disable_pipes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da93ca58-3f4a-42bd-8c45-cbc4c8ebc4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t= \"\"\"Create a pipeline component. Mostly used internally. To create and\n",
    "add a component to the pipeline, you can use nlp.add_pipe.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e22a1a9f-6ced-4520-9dbd-0de0e3c6aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "with nlp.disable_pipes(\"tok2vec\",\"parser\") as n:\n",
    "    print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8468d6a0-121f-46c6-9980-d49a32fdb518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipe line have limited disable system(it disable for limitted time) like here after with end then all pipe line will remain same.\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4623820-8d25-42ae-9e33-0a3c4e98bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b6f635a-59a4-4be3-9621-63c8d9285371",
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension(\"author\",default = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca6bb9a7-9a3f-4c6f-a151-18a565ea62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.book = \"Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5eccc1a-e037-4356-ac31-3ef4260c941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension(\"book\",default = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9b02161-fb8d-44b1-8e5b-a9fa9b1d70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Izhar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a sample python Book.\"\n",
    "\n",
    "# Process the text to create a Doc object\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65d77cab-91ba-4eea-9b6f-10237d065c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(doc._.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d1cc61b-71e5-4bb7-83ed-309fa12942d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "print(doc._.book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c94174-1325-4748-bb43-670cee2222ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82feae03-83e3-4399-90c5-c3d88b2be4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science Fiction\n"
     ]
    }
   ],
   "source": [
    "# Adding a custom attribute \"genre\" to the Doc object\n",
    "Doc.set_extension(\"genre\", default=None)\n",
    "\n",
    "# Assigning a genre to a document\n",
    "doc._.genre = \"Science Fiction\"\n",
    "\n",
    "# Accessing the custom \"genre\" attribute\n",
    "print(doc._.genre)  # Output: Science Fiction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a082dc00-462f-4af3-9979-ebc3565b31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Texts = ['How to preorder the iPhone X',\n",
    " 'iPhone X is coming',\n",
    " 'Should I pay $1,000 for the iPhone X?',\n",
    " 'The iPhone 8 reviews are here',\n",
    " 'Your iPhone goes up to 11 today',\n",
    " 'I need a new phone! Any tips?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a322429b-7702-4a08-a94e-7aefbdea4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8d9b63-40b4-4a77-8f17-1f9093c1e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9c6aeb-25ac-49c5-bf2f-f6828a410a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtexts\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0m_AnyContext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mas_tuples\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdisable\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_process\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0m_AnyContext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Process texts as a stream, and yield `Doc` objects in order.\n",
       "\n",
       "texts (Iterable[Union[str, Doc]]): A sequence of texts or docs to\n",
       "    process.\n",
       "as_tuples (bool): If set to True, inputs should be a sequence of\n",
       "    (text, context) tuples. Output will then be a sequence of\n",
       "    (doc, context) tuples. Defaults to False.\n",
       "batch_size (Optional[int]): The number of texts to buffer.\n",
       "disable (List[str]): Names of the pipeline components to disable.\n",
       "component_cfg (Dict[str, Dict]): An optional dictionary with extra keyword\n",
       "    arguments for specific components.\n",
       "n_process (int): Number of processors to process texts. If -1, set `multiprocessing.cpu_count()`.\n",
       "YIELDS (Doc): Documents in the order of the original text.\n",
       "\n",
       "DOCS: https://spacy.io/api/language#pipe\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\izhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\spacy\\language.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.pipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb1f2a9-a8bd-44c6-870e-713cd75989a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import matcher\n",
    "from spacy.tokens import doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc73cf-b260-4c71-828d-e6334a3096fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(Texts):\n",
    "    # Find the matches in the doc\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # Get a list of (start, end, label) tuples of matches in the text\n",
    "    entities = [(start, end, 'GADGET') for match_id, start, end in matches]\n",
    "    print(doc.text, entities)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9000a04-a481-4754-99e8-fa48266f719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "    \n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "        \n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab3246-454f-4784-a973-49822b166294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
